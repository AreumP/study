**2020/10/16** **논문미팅**

* 주제 : **지능형 로봇을 행정서비스에 적용할 수 있는 방안 고안 및 연구**
  * 키워드 : 행정서비스, 생애주기별 정책제안, 공간탐색, 민원응대(주민센터), 안전관련, 분석기술

  * Data : 서울시 빅데이터(통계, 공공데이터), S-dot(도시환경정보), 서울시 챗봇

  * 주제가 기계공학 석사논문과 동떨어진다는 피드백

  * 랩실에서 주로 쓰는 연구방법, 영상팀

  * 사용할 수 있는 기자재, 로봇이 있는지? GPU 좋은 컴퓨터...?!

    1) 머신비전, 딥러닝이용 유틸

     ex) 아마존 고, 영상판독, 진단(의학)

    모바일 로봇+머신비전+사람체킹, 위험도 체킹

    2) 아마존 인공지능 스피커 (대화 data) 

* idea : 통계에서 스페셜모델→차년도 추정

   분석용 가우시안 프로세스(서울시 미세먼지)

   매틀랩 function, python

---

**2020/10/19** **대학원생 미팅**

머신비전 아이템

주제

연구방법

데이터 추출

---

**2021/3/13** **주제 구체화 자료**

* 주제선정
  * 훈련과제 : 지능형 로봇을 활용한 행정업무 활용방안 연구
  *  학업계획서 : 지능형 로봇을 행정업무에 도입할 수 있는 방안 고안 및 연구
  * 연구계획서 : 인공지능을 활용한 교통약자 도시철도 안내 로봇 연구
*  키워드
  *  지능형 로봇, 행정업무(서비스), 교통약자, help

​    

\3. 실제 제공 중인 서비스(0.교통약자 편의시설)

 \- 시각장애인 음성유도기 : 음성으로 위치 및 필요한 안내 설명

 \- 장애인용 자동개집표기

 \- 장애인용 엘리베이터 감시용 영상 감시 장치

 \- 비상 통화 장치

 \- 인터폰장치 : 휠체어리프트 등 시설관리자 호출

 \- 시각장애인 보행경로 안내 설비 : 벽부, 천장 등 시설물 구조 고려하여 설치

​    

\3. 어떤 서비스?

 \- 이동 편의 : 보행환경 인식, 주변 장애물 인식, 

 \- 빠른 판단 : 대상 판단, 분류

 \- 정보 제공 : 편의시설 정보(에스컬레이터, 엘리베이터, 화장실, 개표기 등?)

​    

\4. 유사 논문

 1) 철도역사에서의 교통약자 이동편의를 위한 협동로봇에 관한 연구

   : 철도역사 내에서 이동할 때 편의성을 위해 시작점부터 도착까지 경로안내 및 서비스를 수행하는 시스템인 협동로봇의 기본설계

   : 기본 운영시나리오, 기본사양, 경로안내 주요기술, 타 시스템과의 인터페이스

 2) 교통약자를 고려한 길 안내 서비스 연구

   : 스마트 단말기를 이용한 보행 보조도구로 길안내 서비스 제공

   : 비지시형 경로안내, 주요지점, 주변상황 음성안내 등 기술요구사항 정리

 3) 교통약자의 이동편의를 위한 최적경로 탐색 기법

   : 경사로, 계단 물리적 장애요소 고려하여 최적경로 탐색, 계층적의사결정법으로 중요도 선정하여 퍼지이론으로 방해정도 나타내는 보행방해도 도출

   : 경로에 대한 설문조사를 통해 정성적 평가결과 반영

 4) 머신비전을 이용한 도로상의 보행자 검출에 관한 연구

   : 보행자 인식을 위해 후보지역생성(HG) 단계와 후보지역확정(HV) 단계를 거쳐서 도로위의 보행자를 검출할 수 있는 알고리즘을 제안하였음

   : 후보지역 생성을 효과적으로 처리하기 위해 보행자 부근에 생성되는 에지 정보의 기하학적 특성 이용, 후보지역 내에 보행자가 몇 명이 포함되어 있는 지를 판단할 수 있도록 대칭 히스토그램 방법을 제안

   : 후보지역 확정단계에서는 수정된 GA에 기반한 SVM 분류기를 사용하여 보행자 영역을 확정

 5) 시각장애인을 위한 합성곱 신경망 기반의 보행환경 인식연구

   : 차로, 보도, 점자블록, 횡단보도 4가지로 분류

   ※ 연구환경 : Intel i5-3230M, python, tensorflow, open CV

  \- 신경망 구성 : 7개 layer, 5개 conv layer, 2개 FC layer

  \- 데이터셋 : 40,000장

​    ▶학습데이터 : 38,600장, 시험데이터 : 400장, 검증데이터 : 1000장

  \- 목적 : 편의시설이 어려움, 보행환경이 더 어려움, 편의시설 문제점이 많아 보행환경 정보제공을 위해 인공지능 사용함

  \- 데이터 취득 : 후면카메라로 프레임추출

  \- 보행환경 인식 알고리즘

​    ▶ 합성곱 계층 : 합성곱 연산+activation func(ReLU) + Maxpooling

​    ▶ Fully Connected layer 1 : drop_out+Softmax

​    ▶ Fully Connected layer 2 : optimizer(Adam)

 6) 깊은 신경망 기반 객체 인식기를 활용한 교통 약자 인식(머신러닝 모델비교)

  \- 건널목 건널 때 교통약자가 지나가면 인식하여 시간을 길게 연장하기 위해 교통약자 인식 모델 평가함

  \- Mobility-aids 데이터를 사용하여 Faster RCNN모델, YOLO v5 모델에 학습시켜 빠른 판단시간을 확인함

  \- YOLO v5 모델이 교통약자 인식에 더 적합하다 판단

  \- Mobility-aids 데이터(외국 병원데이터) : 휠체어, 지팡이, 보조기구, 일반인으로 분류

 7) 보행 가능 구역 인식 모델

  \- 자전거도로, 주의구역, 횡단보도, 점자블록, 차도, 인도 등 보행가능 Surface Masking데이터를 활용하여 분류

 8)

​    

\5. 교통약자 분류

 \- 고령인

 \- 영유아, 임산부

 \- 장애인 : 지체, 뇌병변, 시각, 청각

​    

\6. Idea

 \- 목적 : 이동편의

 \- 지하철 역사 내에서 길 판별 : 인도, 점자블록, 승강장, 스크린도어

 \- 사람 : 노인, 영유아(키), 휠체어, 유모차, 보행보조기구

 \- 결과물 : 알고리즘? 머신러닝 모델구현? 

​    

\7. 데이터허브

 \- AI hub 한국사람 얼굴

---

**2021/3/16** **주제 구체화**

1. 연구주제 : 인공지능을 활용한 교통약자 도시철도 안내 로봇 연구

    시각장애인 도시철도 이용환경 인식시스템 연구

   시각장애인 지하철 (길 찾기) 안내 시스템 연구

2. 키워드 : 시각장애인(교통약자, 시각약자), 물체탐색, 시스템

3. 대상 : 사람, 승강장, 스크린도어(or 지하철) 개폐문, 카드태그기, 계단, 에스컬레이터, 기타장애물

4. 방법 : 이미지 취득 -> 이미지태깅 -> Yolo 머신러닝 -> 피드백

5. 추가 아이디어 : 물체인식(여러장)으로 가까워지는 사람 판별(동적 대상)

6. 교수님 추천 가이드라인

    1) Annotation으로 물체 태깅

    2) 여러 사진 비교(3~4장)로 optical flow 분석하여 충돌위험 감지(사람 등)

7. 데이터수집
   - 구글이미지
   -  실제 동영상(지하철 플랫폼 근처)

---

**2021/3/17** **논문공부**

▶ Do

 \- Pycharm 설치(대학생 라이센스)

 \- 텐서플로, 판다스, open cv, 케라스 모두 오픈소스 라이브러리

 \- 어차피 다 파이썬 기반 라이브러리들

 \- 개발환경은 파이참, 스파이더 등이 있음

 \- Git은 오픈소스 공유하는 게시판 같은 곳

​    

* 데이터 수집
  *  1440*1440 픽셀의 동영상 촬영(개표기, 플랫폼, 스크린도어, 점자블록)
  * 영상을 이미지로 변환 및 사이즈 조정 : Open CV이용

\2. 데이터 가공

 1) Annotation

 2)

​    

**2021/3/18, 3/21, Open CV** **공부**

기본개념

영상을 구성하는 최소 단위를 픽셀(pixel)= 화소

가로w, 세로h인 영상 크기(w*h)

M개의 행, N개의 열(MxN 행렬)

좌표의 시작을 0부터 표현해서 zero-based 표현

\2. 그레이 스케일 영상과 컬러 영상

 \- 컴퓨터 비전에서 주로 그레이 스케일 영상, 트루컬러 영상 사용

 1) 그레이 스케일 영상 : 밝기정보로만 구성된 영상, 회색조 영상

  \- 밝기정보를 256단계로 구분하여 표현함

  \- 하나의 픽셀은 0~255 사이의 정수 값(0:검은색, 255:흰색)

  \- 그레이스케일 레벨 : 0~255 범위

  \- 그레이 스케일 값 저장하기 위해 c/c++에서 unsigned char 자료형 사용

 unsigned char 자료형 : 1byte의 크기, 부호 없는 8bit 정수 값 저장 가능

 unsigned char 자료형 이름 재정의

   **- window: typedef unsigned char BYTE;**

  **- opencv : typedef unsigned char uchar;**

​    

 2) 트루 컬러 영상 : 다양한 색상을 표현할 수 있는 영상

 \- R,G,B 세 개의 성분조합으로 픽셀 값 표현함

 \- 각각의 색상 성분은 0~255 사이의 정수값으로 표현됨

 \- 하나의 픽셀은 unsigned char 자료형 세 개를 이용하여 표현 할 수 있음

   ex) (R,G,B) = (0,0,255) 0은 색이 없음, 255는 full color

\3. OpenCV 개요

 1) OpenCV 는 오픈소스로 개발되고 있는 컴퓨터 비전 및 머신러닝 라이브러리

  \- 기본적인 영상 파일 입출력, 영상의 화질 향상, 객체 검출과 인식, 추적, 3차원 비전문제 해결 등 기능 제공, kNN,SVM 같은 머신러닝 알고리즘도 제공

  \- 기본적으로 C/C++ 언어로 작성, python, java 등 인터페이스도 제공함

  \- 대부분 병렬처리로 동작

  \- Open CV 라이브러리는 BSD 라이선스 : 학계연구용, 상업용 사용 가능

  \- 주요 모듈

| 영상 입출력            | 전처리        | 특징추출           | 객체 검출, 영상 분할 | 분석 : 객체 인식, 포즈 추정, 움직임 분석, 3D 재구성 | 화면 출력, 최종 판단 |
| ---------------------- | ------------- | ------------------ | -------------------- | --------------------------------------------------- | -------------------- |
| core,videoio,imgcodecs | imgproc,photo | imgproc,features2d | imgproc, objdetect   | calib3d, video,stitching, ml, dnn                   | highgui, ml, dnn     |

 2) 주요 함수 설명

  \- imread() : filename 영상 파일을 불러와 Mat 객체로 변환하여 반환, filename은 경로 불러오기

​       : flags – 영상 파일을 불러올 때 사용할 컬러 모드와 영상크기를 지정하는 플래그

​             ex) IMREAD_UNCHANGED, GRAYSCALE 등

  \- imwrite() : Mat 객체에 저장되어 있는 영상 데이터를 파일로 저장

​      : img 변수에 저장되어 있는 영상 데이터를 filename 이름의 파일로 저장

​    

 3) 동영상 파일 다루기

  \- 동영상 : 정지영상(프레임)을 압축하여 파일로 저장한 형태

  \- 동영상 처리하는 작업은 동영상에서 프레임 추출 후 영상처리 기법을 적용하는 형태로 이루어짐

  \- VideoCapture 클래스 사용하여 프레임 받아옴

\4. Git Hub 사용법

 1) GitHub? : 소프트웨어 개발 프로젝트를 위한 소스코드 관리 서비스

​    

**2021/3/24** **이미지** **Annotation**

이미지 분류 종류

 1) Classification : 입력으로 주어진 이미지 안의 객체 Object 의 종류(Class 또는 Label 이라고 불림)를 구분하는 행위이다.

 2) Localization : 이미지의 두번째 경우 같이 모델이 주어진 이미지 안의 Object 가 이미지 안의 어느 위치에 있는지 위치 정보를 출력해주는 것으로, 주로 Bounding box 를 많이 사용하며 주로 bounding box 의 네 꼭지점 pixel 좌표가 출력되는 것이 아닌 left top, right bottom 좌표를 출력한다.

 3) Object Detection : 보편적으로 Classification 과 Localization 이 동시에 수행되는 것을 의미한다. 모델의 학습 목적에 따라서 특정 Object 만 Detection 하는 경우도 있고 (이 경우 학습시 검출하고자 하는 Object 에 대한 학습정보만 입력함), 여러개의 객체를 검출하는 Multi object detection 모델을 만들기도 한다. 종종 object deteciton 은 localization 의 의미로만 사용되는 경우도 있다. 이 경우는 이미지 위에 모델이 학습한 object 위치만 bounding box 로 표현되고 class 종류는 구분하지 않는 경우이다.

 4) Object Recognition : 대개의 경우 Object detection 과 같은 의미로 쓰인다. 그러나 detection 은 object 의 존재 유무만 의미하고 recognition 이 object 의 종류를 아는 것이라고 해석하여 object detection 이 object recognition 보다 더 작은 의미로 해석되는 경우도 종종 있다.

 5) Object Segmentation : object detection 을 통해 검출된 object 의 형상을 따라서 object 의 영역을 표시하는 것이다. 보통 이미지의 각 pixel 을 classification 해서 위와 같은 결과 값을 도출한다. 단순히 전경 foreground 와 배경 background 를 구분하는 용도로 쓰이기도 한다.

 6) Image Segmentation : Image segmentation이란 이미지의 영역을 분할하는 것이다. 이런 분할된 영역들을 적당한 알고리즘을 사용해 합쳐서 object segmentation 을 수행한다.

 7) Semantic Segmentation : Semantic segmentation이란 Object segmentation을 하되 같은 class 인 object 들은 같은 영역 혹은 색으로 분할하는 것이다.

 8) Instance Segmentation : Semantic segmentation 에서 한발 더 나아가서, 같은 class 이더라도 서로 다른 instance 들을 구분해주는 것이다.

​    

​    

**2021/3/25 What to do?**

<To do list>

이미지 용량 줄이기 : 머신러닝에서 많이 사용하는 이미지 크기는 32X32 ,64X64 ,96X96 ,245X256 

video에서 이미지 추출하기(촬영 영상)

흑백 이미지

데이터 수는 얼마나 더? 

이미지 라벨링 해보기(아무거나..)

​    

<Test>

64x64픽셀로 변환 시 화질이 매우 낮아짐 -> 동영상에서는 괜찮음

256x256픽셀은 꽤 자세함

 \- 96픽셀까지는 soso

 \- 픽셀깨져도 괜찮은지?

image_sharp의 경우 빛에 의해 경계선이 무뎌졌을 때 이용하는 것이 좋아 보임

\4. 동영상에서 영상 캡처: 프레임수가 작을수록 많은 화면 캡쳐됨(10프레임~30프레임 사이)

\5. 저장한 이미지 불러와서 gray scale 처리하기

​    

**2021/4/2 OpenCV** **강의**

영상 파일 형식 특징

 \- BMP : 픽셀데이터를 압축하지 않고 그대로 저장

 \- JPG : 주로 컬러 영상 저장, 손실압축

 \- GIF : 256색상 이하의 영상을 저장

 \- PNG : 무손실 압축(많이 사용됨)

\2. OpenCV : 머신러닝 라이브러리

\3. VS code 환경설정

 1) python 인터프리터 고르기 : ctrl+shift+P

\4. opencv는 영상 데이터를 numpy.ndarray로 표현

 \- ndim : 차원 수, len(img.shape)과 같음

 \- shape : 각 차원의 크기, (h,w) 또는 (h,w,3)

 \- size : 원소의 개수

 \- dtype : 원소의 데이터 타입. 영상 데이터는 uint8

**2021/4/4 Annotation**

어노테이션 작업 ing

 \- labeling tool : labelimg

 \- 기준

person(사람)

block(점자블럭)

road(길)

stair(계단)

elevator(엘베)

tagging(개찰구)

number(숫자)

symbol(장애인표시 등)

gap(지하철 바닥 갭)

escalator(에스컬레이터)

screen door(스크린도어)

subway(지하철)

 \- 문제점 : 데이터가 주로 road, block, stair위주임

 \- 에스컬레이터 영상 얻기가 생각외로 쉽지않음

 \- optical flow 대입해보려고 했는데 사람의 방향성을 얻는 데이터가,,,,?

 \- 숫자데이터도 같이 써보려고 했는데 64x64에서는 글씨가 깨짐...gg

​    

\2. 해야할 것

 1) 일정 정리

 2) 데이터정리

 3) opencv 강의

 4) 선행연구 자료 정리(하루 한 개)

​    

**2021/4/5 Study**

opencv 강의 1개

 \- ROI : region of interest(관심영역)

\2. labeling : 607까지

\3. 논문하나 정리함.ㅎ

​    

**2021/4/6 Study**

labeling : 839번

강의 2개

 \- copy, 그리기 함수

​    

**2021/4/8 Study**

강의

 \- cv2.VideoCapture 클래스 : 카메라, 동영상으로부터 프레임을 받아오는 작업을 클래스 하나로 처리

 \- cv2.VideoWriter 클래스 : 일련의 프레임을 동영상 파일로 저장할 수 있음. 프레임은 모두 크기와 데이터 타입이 같아야 함

 \- Fourcc(4-문자코드, four character code) : 동영상 파일의 코덱, 압축방식, 생상, 픽셀 포맷 등을 정의하는 정수 값

\2. 선행연구 및 차별성(기공프 수업)

 \- 차별성을 부각시켜서 작성해야 논문의 깊이가 깊어짐

 \- 선행연구 내용정리 및 차별성 작성해보기!!!

 \- background로 논문에 사용됨

 \- 연구 방법이랑 결과도 작성해보기!!!

 \- 결과 예측을 통해 방향성도 정해짐

 \- 실제 결과랑 비교해서 disscution 작성

 \- 결과만 뽑아내는건 실험보고서고 결과를 통해 왜 나왔을까? 다른 결과가 나오면 분석?!!?

 \- 최종 결과는 짧은 논문형태의 보고서

\3. 라벨리이잉.. : 1077번,video_full : 28번까지

​    

**2021/4/10 Study**

opencv 인강

capcode 수정

라벨링 1700번부터

​    

**2021/4/11 Study**

1. labeling : 1960부터

- 데이터 라벨링 잘 하고 있는지 확인필요
-  무엇으로? 어떻게?

2. opencv와 컬러 영상

 \- numpy.ndarray로 표현, BGR순서

 \- cv2.split (색상 채널 분리)

 \- cv2.merge(색상 채널 결합)

 \- 그레이스케일 변환 : 데이터 저장용량 감소, 데이터 처리속도 향상/색상정보 손실

 \- 히스토그램(Histogram) : 영상의 픽셀 값 분포를 그래프의 형태로 나타낸 것

   cv2.calcHist(히스토그램 구하기)

​    